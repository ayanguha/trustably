{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":"Build Safe, Reliable, and Trustworthy AI Solutions <p>       We help businesses to build, deploy and run better AI systems.     </p>          Learn More                 Playbook"},{"location":"#solutions","title":"Solutions","text":"AcceleratorsServices Deep Monitoring <p>Deep and effective tracing, instrumentat each AI interaction with right level of tracing to capture Chain of Thought, Reasoning and useful metrics via a single pane of glass to report and analyse - leading to better measure for Quality, Safety, Performance and Efficacy of compound AI systems</p> RAG - Combine &amp; Compare <p>Combine various LLM, Vector Database and Embedding models with Knowledge Sources and Retrieval techniques to measure end to end performance</p> Assessment Playbook <p>A definitive guide to assess AI platform maturity and develop a systemic, risk-graded action roadmap to enhance AI maturity and readiness</p> <p>A comprehensive AI enablement framework combining industry benchmarks to help you with mitigating potential risks effectively over short, medium and long term.</p> AI Risk Assessment &amp; Reporting <p>A well defined risk assessment aligned with Well-Architecture Review Framework, covering DataOps, ModelOps and DevSecOps</p> Solution Quality Assessment <p>Ensure the highest standards of quality in your AI solutions through rigorous technical and functional validation processes. Help you to develop an end to end well understood value chain, with strong focus on fit-for-purpose, ROI-driven AI solutions that align with your business goals and objectives.</p> <p>Speak with an advisor</p>"},{"location":"#thoughtleadership","title":"Thoughtleadership","text":"<ul> <li> <p> Agentic AI and Observability</p> <p>How to build observability into your agentic AI systems from day one</p> <p> Read</p> </li> <li> <p> If it is not measured, it didn't happen</p> <p>Measure quality and performance in distributed and compoundAI systems.</p> <p> Read</p> </li> <li> <p> Plan for the Worst, Hope for the Best</p> <p>Prepare for potential failures in AI systems; and how to prevent them.</p> <p> Read</p> </li> </ul> <p>Read Our Blogs</p>"},{"location":"core/","title":"AI Enablement Framework","text":""},{"location":"core/#introduction","title":"Introduction","text":"PrefaceRationale of this document <p>Artificial intelligence (AI) represents a material technological capability with significant implications for enterprise operations, risk posture, and societal impact. While AI lowers barriers to innovation and enables scalable solutions across business functions and customer segments, it simultaneously introduces a distinct and evolving set of risks. </p> <p>In this rapidly changing technology landscape, the single most important factor for success is building safe, reliable, and trustworthy AI and Agentic solutions. At the same time it is often the most underrated aspect and often overlooked in the noise. We are here to help you navigate this complexity with clarity and confidence.</p> Opinion <p>As AI-enabled and AI-augmented systems become easier to develop and deploy, the complexity of ensuring their reliability, safety, and trustworthiness increases correspondingly, requiring deliberate governance and oversight.</p> <p>Contemporary AI solutions are increasingly underpinned by generative AI (GenAI) technologies, including large language models (LLMs). These models are inherently non-deterministic, producing probabilistic outputs rather than predictable, repeatable results. Traditional software engineering, risk management, and control frameworks, however, are primarily designed around deterministic system behavior. As a result, existing standards, assurance practices, and control mechanisms are often insufficient to fully address the risk characteristics introduced by AI systems. This creates a material gap between established technology risk management approaches and the emerging risk profile associated with AI adoption.</p> <p></p> <p>AI-related risks are not confined to individual systems or use cases. They arise across system interactions, including integrations between AI and traditional applications, interactions among multiple AI systems, and human\u2013AI decision-making processes. In addition, the increasing adoption of agent-based AI architectures\u2014where systems are granted varying degrees of autonomy to initiate actions\u2014introduces new dimensions of operational, ethical, and compliance risk. The emergence of multi-agent ecosystems further compounds these challenges by increasing system interdependence, opacity, and potential for cascading failure modes.</p> <p>As AI systems scale in autonomy and complexity, enterprises must anticipate a corresponding amplification of both value and risk. Effective AI governance therefore requires extending existing enterprise risk management frameworks to address AI-specific risks, supported by clear accountability structures, robust controls, continuous monitoring, and lifecycle-based assurance. Without such measures, organizations may struggle to balance innovation objectives with regulatory compliance, operational resilience, and stakeholder trust.</p> Opinion <p>Mapping AI system interactions with real world is a novel aspect - and it is for the first time human intelligence is facing the possibility of interacting with potentially similar or more competent systems. </p> Acknoledgement <p>It is important to note the acknoledgement to all frameworks noted here and this document should be seen an extension and assimilation of them, rather than a competing one.  s</p> <p>The traditional software industry has been shaped by well-established standards, control frameworks, and best practices that govern system design, delivery, and risk management. A natural question, therefore, is whether these existing practices can be extended to address the risks introduced by generative AI (GenAI) systems. This extension-based approach underpins frameworks such as the NIST AI Risk Management Framework and AWS Well Architected Review (WAR), among others. Both frameworks provide comprehensive, enterprise-grade risk management structures that have been adapted to incorporate AI- and GenAI-specific considerations.</p> <p>While these frameworks offer strong alignment with existing enterprise governance, risk, and compliance models, closer examination reveals that some foundational and novel risk characteristics of GenAI systems are insufficiently articulated when treated as incremental extensions of traditional software risk. In particular, aspects such as non-deterministic behavior, emergent system properties, model dependency risks, and human\u2013AI interaction dynamics can be diluted within generalized control taxonomies. The objective of this document is therefore to synthesize these frameworks in a way that preserves a holistic, enterprise-wide perspective while explicitly addressing the unique risk requirements of GenAI-enabled systems.</p> <p>In addition, there are platform-specific frameworks, such as the Databricks AI Security Framework (DASF) 2.0, which focus on identifying and mitigating AI-related security risks through platform-native capabilities. While such frameworks are highly effective in articulating concrete technical controls and security patterns, they are inherently scoped to specific platforms and tend to be narrowly focused and deeply technical. As a result, they may be less accessible or actionable for broader governance, risk, and business stakeholders.</p> <p>Accordingly, this document also incorporates elements of DASF to strike an appropriate balance between technical rigor and enterprise-level risk governance. By integrating platform-level control insights with higher-level risk management frameworks, the document aims to support informed decision-making across both technical and non-technical audiences, while maintaining alignment with business objectives, regulatory expectations, and risk appetite.</p>"},{"location":"core/#enablement-framework","title":"Enablement Framework","text":"Intended AudienceIntended Use <p>This framework is designed to be used by a wide range of personas according to scope of their typical responsibilities. </p> <ul> <li>Executive Leaders can use AEF as a guide to infuse AI in their organisation to drive technical and cultural maturity</li> <li>Governance leaders can use AEF as an equivalent of risk-graded operational manual to roll out AI with right level of controls </li> <li>Product and Portfolio managers can use AEF as a broad picture of all required components of a successful AI rollout to make sure right level of collaboration and dependency management </li> <li>Practitioners can use AEF as a detailed guide to ensure AI system is built, configured, operated and managed in right way. </li> </ul> <p>Personas</p> <p>AI enablement framework (This document) is aimed to produce single framework for practiotioners, leaders and other actors of any AI system. This document is intented to use for following broad purposes, while not limiting to any other valid scenarios. </p> Strategy and Conceptualisation <p>This framework can be used to illustrate requirements for a specific AI system implementation. It will help to understand how to prioritise certain aspects of the system and corresponding residual risks accrued - and conciously plan accordingly. </p> Design and Decide <p>This framework is intented for architects and solution designers to understand the wide impacts of the solution components - and should help to choose specific platform based on capbilities and prioritised requirements. </p> Risk Assessment and Improvements <p>This framework can be utilised to assess existing design and implementation of specific AI use case and help to improve risk and security postures by implementing best practice actions. </p> <p>Learn More</p> AI Maturty Model Uplift <p>This framework can be utilised by AI leaders to align the organisation with a clear, comprehensive, industry-standard maturity model for AI system and platfor and guide them through using a well callibrated roadmap across four stages:</p> <ul> <li>Explore: The organization is assessing the relevance and potential value of AI across priority business domains. AI initiatives are exploratory, use-case driven, and typically delivered disjointly. </li> <li>Experiment: The organization is actively piloting AI solutions through structured experiments and controlled deployments. Early AI platform components emerge, supported by initial standards for data access, model development, and security. </li> <li>Enable: The organization establishes a standardized AI platform and operating model to support consistent and repeatable AI delivery. </li> <li>Embrace: AI capabilities are fully integrated into the enterprise\u2019s core platforms, decision processes, and operating model. </li> </ul> <p>This maturity model is consistent with industry-known AI maturity models such as AWS Prescriptive Guidance Model, MIT Sloan Model or similar. Trustably framework is designed to seamlessly work with such models. </p>"},{"location":"core/#components-relationships","title":"Components &amp; Relationships","text":"<p>This section describes all components of AEF. It is important to note that these compoents influence each other in subtle but significant ways - ie actions taken to address issues in one components can impact other compoennts - potentially both positive and negative ways. The relationships are described here, however the actual impacts are subjected to specific constraints and situations under which this framework is adopted. </p> <p></p> TraitsFocus AreasSystem Lifecycle PersonasBest Practices <p>AI system traits describe a comprehensive list of key requirements which must be pursuaded and achieved as much as possible. </p> <p>Learn More</p> <p>Focus areas are the aspects of AI systems that should be influenced to address potential issues and challenges. </p> <p>Learn More</p> <p>Like any other software solution, AI systems follow a design, development, deployment and enhance lifecycle spanning across data, model and automation realms. This unique and wider scope requires to combine best practices of DataOps, ModelOps and DevSecOps for a successful roll out of a trustworthy and valuable AI system. </p> <p>Learn More</p> <p>As noted in the preface, AI systems interacts with each other, with traditional systems and with humans - spanning the scope of actors to consider for a complex agentic AI system to a very wide set of personas. These scope can then be further divided into core actors, adjacent personas and external personas depending on their involvement in design, development and utilise such system</p> <p>Learn More</p> <p>A list of best practices across various components are curated for adoption. This is also presented via a playbook for easy navigation and discovering relationships between individual actions. </p> <p>Learn More</p>"},{"location":"core/#more-details","title":"More details","text":"LimitationsDefinitionsAcknowledgement <p>This framework deliberately limits in certain areas, namely but not limited to:</p> <ul> <li> <p>Inherent Advarserial Attacks: The adversarial attacks are evolving as the LLMs are getting traction. This framework does not address such attacks because they are inherent to model arcitecture and generally out of scope for model consumers</p> </li> <li> <p>Inherent AI Safety issues: For same reasons, inherent AI safety issues such as Goal misalignment if not addressed by this framework</p> </li> <li> <p>Cloud Platform: This framework does not address any cloud platform issues explicitly, and delegates such issues to appropriate security and/or architecture best practices. It is strongly suggested that this framework should be used along with other appropriate best practices. </p> </li> <li> <p>Data Platform: While this framework provides a significant overlap with data platform capabilities and thus covers  largel part of data operations, this framework does not explicitly address underlying data platform design aspects such as data modelling, data processing, data storage etc. It is strongly suggested that this framework should be used along with other appropriate best practices. </p> </li> </ul> Expand <p><code>TBD</code></p> Acknowledgement <p>This work draws on ideas, models, and concepts from existing research and industry sources. These materials have helped shape the thinking and structure of the approach presented here, while any adaptations or interpretations are our own. All sources are used with respect for their original intent and applicable attribution standards.</p> <p>Similarly, we would like to be acknowledged in case this work is used or inspired other work. </p>"},{"location":"focus_areas/","title":"Focus Areas","text":"<p>AI Enablement Framework organises risks, best practices and maturity models across <code>5</code> core focus areas - such as Security, Observability, Platform, Governance and Culture. Each of these high level focus areas are broken down to subsequent groups which provides clarity and targeted activities for organisations to adopt. </p> <p></p>"},{"location":"focus_areas/#culture","title":"Culture","text":"Intention of Use <p>TBD</p> Operating Model <p>TBD</p> Active Awareness <p>TBD</p>"},{"location":"focus_areas/#governance","title":"Governance","text":"AI Risk Management <p>TBD</p> Artefact Inventory <p>TBD</p> Change Management <p>TBD</p> Standards and Policies <p>TBD</p>"},{"location":"focus_areas/#observability","title":"Observability","text":"Define and Instrument <p>TBD</p> Evaluate and Measure <p>TBD</p> Monitor and Action <p>TBD</p>"},{"location":"focus_areas/#security","title":"Security","text":"Access Control <p>TBD</p> Data Classification and Controls <p>TBD</p> Safe Guards &amp; Guardrails <p>TBD</p>"},{"location":"focus_areas/#platform","title":"Platform","text":"Automation <p>TBD</p> Integration and Collaboration  <p>TBD</p> Resilience <p>TBD</p>"},{"location":"lifecycle/","title":"AI System Lifecycle","text":"Design <p>The Design phase establishes the foundational intent, scope, and governance posture of the AI solution. This includes defining business objectives, value hypotheses, target users, decision boundaries, and ethical considerations. Architectural principles, security-by-design requirements, data classification, and regulatory obligations are incorporated upfront to ensure compliance and traceability. Clear ownership, funding accountability, and success criteria are formalized to support downstream assurance activities.</p> DataOps <p>DataOps represents the governed, end-to-end management of data assets that underpin AI and analytics systems, encompassing both data sourcing and data preparation activities. It establishes standardized controls for data acquisition, validation, transformation, lineage, and stewardship to ensure data is trustworthy, compliant, and fit for purpose. Operating as a cross-functional capability, DataOps enforces alignment with enterprise data governance, security, privacy, and regulatory requirements while enabling scalable and repeatable data pipelines. Through automation, monitoring, and accountability mechanisms, DataOps reduces operational risk, improves data quality, and provides a reliable foundation for downstream model development and decision-making.</p> Data Sources <p>This section governs the identification, acquisition, and authorization of data inputs used across the AI lifecycle. Data sources are assessed for quality, provenance, sensitivity, licensing constraints, and regulatory compliance (e.g., privacy, data residency, sectoral obligations). Controls are established to ensure lawful access, appropriate consent, and alignment with enterprise data governance standards. Ongoing monitoring ensures continued fitness-for-purpose as source systems evolve.</p> Data Preparation <p>Data Preparation focuses on transforming raw data into model-ready datasets through cleansing, normalization, enrichment, and feature engineering. This stage enforces data integrity, bias mitigation, lineage documentation, and reproducibility controls. Governance oversight ensures that preprocessing decisions are transparent, auditable, and aligned with approved use cases. Data handling practices are validated against security, privacy, and retention policies.</p> AI/MLOps <p>AI/MLOps is the enterprise capability responsible for the governed lifecycle management of AI and machine learning models, encompassing model selection, evaluation, deployment, and ongoing performance oversight. It establishes standardized processes, tooling, and controls to ensure models are developed, validated, operated, and evolved in a consistent, secure, and auditable manner. AI/MLOps enforces alignment with enterprise risk management, security, compliance, and responsible AI principles, while enabling scalable and repeatable model operations. By integrating monitoring, automation, and human-in-the-loop governance, AI/MLOps ensures models remain performant, reliable, and compliant throughout their operational lifespan.</p> Model Selection &amp; Evaluation <p>This section governs the selection of algorithms, architectures, and training approaches appropriate to the defined business and risk context. Models are evaluated against standardized criteria including accuracy, robustness, explainability, fairness, and operational constraints. Comparative testing, validation methodologies, and approval gates are applied to ensure defensible model choices. Decisions are documented to support auditability and regulatory review.</p> Model Performance Management <p>Model Performance Management ensures continuous oversight of model behavior throughout its lifecycle. Performance metrics, drift indicators, bias signals, and reliability thresholds are defined and monitored. Governance controls mandate periodic reviews, retraining triggers, and escalation procedures when performance deviates from approved tolerances. This function supports accountability for ongoing model risk and business outcomes.</p> DevSecOps <p>DevSecOps is the enterprise capability that embeds security, risk, and compliance controls across the design, build, deployment, and operation of AI-enabled platforms and services. It integrates secure engineering practices, automated control enforcement, and continuous assurance into development and operational workflows, ensuring security is treated as a shared responsibility rather than a downstream activity. DevSecOps establishes consistent standards for identity, access management, infrastructure security, code integrity, and vulnerability management across environments. By aligning with enterprise security architecture and governance frameworks, DevSecOps enables resilient, compliant, and scalable delivery of AI systems while maintaining a strong and measurable security posture.</p> Deployment &amp; Serving <p>Deployment &amp; Serving governs the controlled release of models into production environments. This includes infrastructure security, access control, version management, and integration with enterprise systems. Approval workflows ensure that only validated and authorized models are deployed. Runtime safeguards, logging, and observability mechanisms are implemented to maintain operational resilience and compliance.</p> Automation <p>Automation addresses the orchestration of pipelines across data ingestion, training, testing, deployment, and monitoring. Governance ensures automation is implemented with appropriate guardrails, human-in-the-loop controls, and exception handling. Automated processes are designed to reduce operational risk while preserving transparency and intervention capability. Change management and rollback procedures are embedded to maintain system stability.</p> Enhance and Operate <p>This section represents the steady-state operation and continuous improvement of the AI system. It includes incident management, user feedback incorporation, cost optimization, and capability enhancement. Governance mechanisms ensure changes are assessed for risk, approved through formal controls, and aligned with strategic objectives. This phase reinforces accountability for long-term value realization and responsible AI operation.</p>"},{"location":"personas/","title":"Personas","text":"<p>An AI system is easy to conceptualise and quickly developed. However to scale and sustain such system in a trustworthy manner require a wide array of personas actively collaborating. This section lists typical roles across the organisation, divided into core, adjacent and external - depending on their level of active participation in developing and managing the system. </p> Note <ul> <li>Not all these roles are required to start AI journey. As the organisation transitions across various levels of maturity, more of these personas will be needed to manage and operate. </li> <li>It is generally common, and even desired, that some these personas are assumed by same person. It is still important to recognise the role they are performing so that required responsibilities can be carried out correctly </li> </ul>"},{"location":"personas/#core-personas","title":"Core Personas","text":"AI Solution Designer <p>AI Solution Designers are responsible for translating business objectives and requirements into coherent AI solution concepts, including agent roles, workflows, and interaction patterns. They define how agentic AI capabilities are embedded into business processes and decision flows. This role balances functional effectiveness, usability, and risk considerations at the solution level. AI Solution Designers collaborate closely with architects, product managers, and business stakeholders to ensure alignment with enterprise standards. They also ensure that design choices support explainability, controllability, and appropriate human oversight. Their work directly shapes how value and risk are realized through agentic systems.</p> AI Architects <p>AI Architects define the end-to-end technical architecture for agentic AI systems, including models, agents, orchestration layers, integrations, and control mechanisms. They ensure architectural alignment with enterprise standards, scalability requirements, and security principles. This role is accountable for addressing non-determinism, autonomy, and emergent behaviors through appropriate architectural patterns. AI Architects evaluate trade-offs between capability, performance, and risk exposure. They work closely with enterprise and cloud architects to ensure ecosystem consistency. Their decisions materially influence system resilience and governability.</p> Business Owners <p>System Owners hold accountability for the overall lifecycle, performance, and risk posture of agentic AI systems in production. They are responsible for ensuring systems meet business objectives while operating within approved risk appetite and compliance boundaries. System Owners approve use cases, changes, and operating conditions for AI agents. They coordinate across technical, legal, and operational teams to manage incidents and escalations. This role ensures clear ownership for outcomes driven by agentic behavior. System Owners serve as the primary point of accountability to executive leadership.</p> Data Engineers <p>Data Engineers design, build, and operate data pipelines that supply agentic AI systems with reliable and timely data. They ensure data availability, quality, and lineage across the AI lifecycle. This role implements controls for data ingestion, transformation, and access. Data Engineers collaborate with data architects and ML teams to support scalable and secure data flows. Their work directly impacts model performance and agent behavior. They are critical to operational stability.</p> Data Scientists <p>Data Scientists develop analytical models and experiments that inform or power agentic AI capabilities. They explore data patterns, define features, and evaluate model behavior. This role contributes to understanding model limitations, biases, and uncertainties. Data Scientists work closely with ML and AI engineers to transition models into production. They support performance monitoring and continuous improvement. Their insights shape decision quality and system effectiveness.</p> Data and AI Architects <p>Data Architects define the enterprise data structures, standards, and governance models supporting agentic AI systems. They ensure consistency, interoperability, and compliance across data domains. This role aligns data design with business semantics and regulatory requirements. Data Architects guide data platform evolution to support AI workloads. They collaborate with enterprise architects to ensure strategic alignment. Their work enables sustainable and governed data use.</p> Application Developers <p>Application Developers build and maintain the software components that integrate agentic AI systems into business applications. They implement user interfaces, APIs, and orchestration logic. This role ensures secure and reliable interaction between users, agents, and backend systems. Application Developers collaborate with AI engineers to manage invocation patterns and error handling. They are responsible for performance and maintainability. Their work directly affects user experience.</p> Human-Centric Application Designers <p>Human-Centric Application Designers focu\"s on the interaction between humans and agentic AI systems. They design experiences that promote clarity, trust, and appropriate reliance on AI outputs. This role ensures human oversight and intervention points are well defined. Designers account for cognitive load and decision support needs. They collaborate with risk and ethics teams to mitigate misuse. Their work supports responsible adoption.</p> ML Engineers <p>ML Engineers operationalize machine learning models within agentic AI systems. They manage model deployment, versioning, monitoring, and retraining. This role ensures models perform reliably at scale. ML Engineers implement safeguards against model drift and degradation. They collaborate with platform and AI engineers on infrastructure. Their work underpins production stability.</p> AI Engineers <p>AI Engineers build and integrate agentic capabilities, including reasoning, planning, and action execution. They design agent behaviors, tool usage, and control logic. This role addresses reliability and safety in autonomous operations. AI Engineers work closely with architects to implement governance controls. They continuously refine agent performance. Their work defines system autonomy.</p> Product Manager <p>Product Managers define the vision, roadmap, and success metrics for agentic AI products. They balance customer value, feasibility, and risk considerations. This role prioritizes features and manages trade-offs. Product Managers align stakeholders across functions. They ensure outcomes meet business objectives. Their decisions drive adoption.</p> AI Governance Lead  <p>This role owns the enterprise-wide AI governance framework and ensures consistent application across business units. It acts as the single point of accountability for AI risk posture, policy interpretation, and exception management. Without this role, ownership is often fragmented between IT, Legal, and Risk functions. The AI Governance Lead typically reports to a risk or technology executive. This role is especially critical for coordinating decisions related to agent autonomy.</p> AI Security Lead <p>While security responsibilities are often distributed, agentic AI systems introduce novel attack surfaces. This role focuses on AI-specific threats such as prompt injection, data exfiltration, model abuse, and agent hijacking. It coordinates detection, response, and recovery. This role works closely with SOC teams. It is critical for operational resilience.</p> AI Operations (AIOps) Lead <p>This role owns operational response to AI-related incidents, including runaway agents, unintended actions, or harmful outputs. It defines escalation paths and kill-switch mechanisms. Traditional IT incident management is often insufficient for agentic behavior. This role ensures rapid containment and remediation. It protects business continuity.</p>"},{"location":"personas/#adjacent-personas","title":"Adjacent Personas","text":"Data Source Owners/Experts <p>Data Source Owners and Experts are accountable for the accuracy, quality, and appropriate use of specific data assets consumed by agentic AI systems. They define data meaning, constraints, and usage conditions. This role ensures data aligns with business intent and compliance requirements. They support impact assessments when data is used for new AI purposes. Data Source Owners provide critical domain knowledge. Their stewardship reduces downstream risk.</p> Cloud Platform Engineers <p>Cloud Platform Engineers operate the underlying infrastructure supporting agentic AI systems. They ensure availability, scalability, and security of compute and services. This role implements operational controls and monitoring. Cloud Platform Engineers support cost management and resilience. They collaborate with security and architecture teams. Their work ensures production readiness.</p> Cloud Platform Architects <p>Cloud Platform Architects design cloud environments optimized for agentic AI workloads. They define reference architectures, security patterns, and integration standards. This role ensures alignment with enterprise cloud strategy. Cloud Platform Architects address scalability and resilience. They collaborate with AI and enterprise architects. Their designs enable sustainable growth.</p> Enterprise Architects <p>Enterprise Architects ensure agentic AI systems align with enterprise strategy, operating models, and technology standards. They evaluate cross-domain impacts and dependencies. This role ensures coherence across portfolios. Enterprise Architects guide long-term capability evolution. They balance innovation with standardization. Their oversight reduces fragmentation.</p> Enterprise Security Architect <p>The Security Architect defines and governs the security architecture for AI platforms and agentic AI systems across the enterprise. This role establishes security principles and control patterns to address AI-specific risks such as model abuse, data leakage, prompt injection, and unauthorized autonomous actions. They ensure security is embedded into system design through zero-trust, least-privilege, and defense-in-depth approaches. The Security Architect collaborates with AI, cloud, and enterprise architects to align controls with enterprise standards and regulatory requirements. This role is accountable for maintaining a security posture consistent with the organization\u2019s risk appetite.</p> Third Party Solution Providers <p>Third Party Solution Providers deliver external AI models, platforms, or services used within agentic AI systems. They are accountable for meeting contractual, security, and compliance requirements. This role introduces dependency and supply-chain risk. Providers must support transparency and assurance. Their solutions influence system behavior. Effective vendor governance is essential.</p> Change Manager <p>Change Managers oversee organizational readiness for adopting agentic AI systems. They manage communication, training, and stakeholder engagement. This role addresses behavioral and cultural impacts. Change Managers mitigate resistance and misuse. They ensure smooth transition into operations. Their work supports sustained value.</p> Risk Managers <p>Risk Managers identify, assess, and monitor risks associated with agentic AI systems. They ensure risks remain within approved appetite. This role integrates AI risks into enterprise risk frameworks. Risk Managers advise on controls and mitigations. They support decision-making and escalation. Their oversight enables responsible deployment.</p> Quality Assurance Experts <p>Quality Assurance Experts validate that agentic AI systems perform as intended across functional, non-functional, and risk-related dimensions. They design and execute testing strategies that account for probabilistic behavior, edge cases, and failure modes. This role ensures system behavior remains within defined tolerances under varying conditions. QA Experts collaborate with engineering and risk teams to identify defects and unintended outcomes. They contribute to release readiness and ongoing assurance. Their work supports system reliability and user trust.</p> Executive Sponsor <p>The Executive Sponsor provides strategic oversight, funding approval, and organizational sponsorship for agentic AI initiatives. This role ensures alignment between AI investments and enterprise strategy, risk appetite, and ethical commitments. Executive Sponsors resolve cross-functional conflicts and remove organizational barriers. They are accountable for ensuring appropriate governance structures are in place. Their visible support drives adoption and accountability across the organization. Executive Sponsors represent AI initiatives at the board and executive committee level.</p> Decision Authority Role <p>This role formally represents the \u201chuman-in-the-loop\u201d or \u201chuman-on-the-loop\u201d accountability. It has authority to approve, override, or halt agent actions. Without explicit designation, human accountability becomes ambiguous. This role is critical for regulatory defensibility. It ensures meaningful human control.</p> Training &amp; Enablement Owner <p>This role ensures all stakeholders interacting with agentic AI systems are adequately trained. It defines competency requirements and certification. Misuse risk often stems from poor understanding rather than system flaws. This role reduces operational and reputational risk. It supports safe adoption at scale.</p>"},{"location":"personas/#external-personas","title":"External Personas","text":"End User <p>End Users are individuals or groups who interact directly or indirectly with agentic AI systems in the course of performing business or operational activities. They consume system outputs, recommendations, or actions and may initiate inputs that influence agent behavior. End Users are accountable for using AI-enabled capabilities in accordance with defined policies, usage guidelines, and decision rights. Their feedback is critical for identifying usability issues, unintended behaviors, and emerging risks in real-world contexts. End Users also play a role in validating whether agentic AI actions align with business intent and ethical expectations. Proper enablement and training are essential to ensure informed and responsible use.</p> Corporate Functions <p>Corporate Functions such as HR, Finance, and Procurement support agentic AI initiatives through policy, funding, and governance mechanisms. They ensure alignment with corporate controls and ethics. This role enables enterprise-wide consistency. Corporate Functions manage workforce and financial impacts. They support compliance and reporting. Their involvement ensures organizational alignment.</p> Social Stakeholders <p>Social Stakeholders include communities and groups indirectly affected by agentic AI systems. They may experience societal, environmental, or economic impacts. This role represents external perspectives and expectations. Engagement supports social license to operate. Social Stakeholders influence public trust. Their concerns must be considered.</p> Stake/Shareholders <p>Stakeholders and Shareholders have an interest in the outcomes, performance, and risk exposure associated with agentic AI systems. They include internal and external parties affected by AI-driven decisions. This role expects transparency, accountability, and value realization. Stakeholders influence priorities through governance and oversight mechanisms. Their trust is essential for sustained adoption. They are impacted by both benefits and failures.</p> Third Party Solution Consumers <p>Third Party Solution Consumers use agentic AI capabilities exposed by the organization. They rely on system outputs to inform decisions or actions. This role requires clear usage terms and accountability boundaries. Consumers may introduce reputational risk through misuse. Proper onboarding and controls are necessary. Their behavior impacts trust.</p> Legal/Compliance/Audit Experts <p>Legal, Compliance, and Audit Experts ensure that agentic AI systems adhere to applicable laws, regulations, contractual obligations, and internal policies. They assess legal exposure arising from autonomous actions, data usage, and decision-making impacts. This role evaluates governance controls, documentation, and auditability of AI systems. They advise on regulatory readiness, cross-border considerations, and third-party risk. Their involvement is critical in defining acceptable boundaries for agent autonomy. They provide independent assurance to executives and regulators.</p>"},{"location":"playbook/","title":"Playbook","text":""},{"location":"playbook/#playbook","title":"Playbook","text":"<p>This application is a guided assessment for AI Systems. At the end of the assessment, a report will be provided indicating:</p> <ol> <li>Maturity</li> <li>Identified Risks</li> <li>Suggested actions</li> <li>Comprehensive roadmap</li> <li>Technical guidance</li> </ol> <p></p>"},{"location":"risk_actions/","title":"Risk and Best Practices","text":"<p>This section provides a comprehensive list of Suggested actions across Traits, Focus Areas and sub-areas. </p> <p>Go To List</p>"},{"location":"trait/","title":"Traits of AI Systems","text":""},{"location":"trait/#vision-of-ai-systems","title":"Vision of AI Systems","text":"<p>Develop an AI system which should be Trustworthy and Desirable </p> <p></p>"},{"location":"trait/#value-driven-traits","title":"Value-Driven Traits","text":"Strategic <p>The application in discussion must be aligned with strategic objective of the organisation. This trait is critical to guide the prioritisation among many possible ideas and opportunities. </p> Desirable <p>A desirable AI system must be addressing real customer demands or solving real business problems. The value can be realised over multiple iterations of concrete well-defined product roadmap. </p> Viable <p>An operationally efficient AI system must have specific controls in place to optimise and enhance cost and system performance to keep the AI system viable </p>"},{"location":"trait/#trustworthiness-traits","title":"Trustworthiness Traits","text":"Reliable <p>A reliable AI system aspires to perform the tasks as correctly as possible such that it can fulfil business outcomes in an accepted level and able to withstand failures gracefully so that it is aligned with operational controls. Key aspect of reliability is an ability to instrument systems to trace, measure and improve right metrics over a period of time. </p> Valid <p>The minimum requirement of any sestem must be that such systems should be able to behave as expected - at least in the context of their intented use. As the modern agentic AI ecosystem introduces a large amount of non-deterministic behaviour, it is even more important to introduce acceptable measures to evaluate the validity of such systems. </p> Observable <p>Observability is a key element of modern DataOps, MLOps and DevOps - it allows to establish traceability, reproducibility, and continuous improvement in agentic workflows by providing a systemtic approach to maintain artefacts and measuring quality throughout the application lifecycle</p> Resilient <p>Resilliancy is a distinct component which allows AI systems to function normally or degrade gracefully in the face of unexpected - even advarserial - change in the environment they are functioning </p> Safe <p>AI safety is defined - atleast in the context of this framework - as a trait which ensures the AI system does not neagatively impact the environment it is operating in. Safety is often describes a set of risks which, if realised, can have catastrophic outcome, and thus must be managed throughout the design, development, deployment and post-deployment lifecycle</p> Unbiased, Un-Harmful <p>One of the known vulnerability of modern AI models is the bias they pick up during training process. There are many examples where Ai systems exhibits harmful properties even in a non-advarserial settings. It is thus critical to employ a range of guardrails to ensure such behaviour can be continously monitored and acted upon as needed. </p> Explainable <p>Explainable AI systems must provide a representation of inner working of how a particular outcome is arrived. An ancilliary concept is interpretability which is defined by the role of the outcome in context of the task itself. Explainibility and Interpretability enhances the understanding of how the system is performing - leading to higher safety settings. </p> Transparent <p>Transparency is a cornerstone of trustworthyness in a system. The scope of this trait expands throughout the lifecycle - right from design decisions,  data used for training, efficacy of any models used for any specific use case to all the way up to deployment practices, post-deployment monitoring and operating models including model-human interactions. </p> Accountable <p>Accountability clarifies who is responsible for intended use cases, design decisions, technical decisions, how and when an AI system is deployed and what end user decisions were made post-deployment - this provides a clarity around roles and responsibilities across the organisation to promote right focus and collaboration</p> Interoperable <p>Hardly any reasonable moderm agentic AI solution is single sourced - and that necessiates the solution needs to embracy interoperability as a core principle. This helps to create modular and reusable components with clear integration points</p> Secure <p>Security is a fundamental, non-negotiable requirement in any system - espcially AI systems. It is a core trustworthy feature for all types of AI systems - with varying degree of risk profiles across foundational models which uses prompts only, RAG systems which requires enterprise information and autonomous and compound agentic systems which require significant agency on data. </p> Context-Aware <p>Traditional information security and authorization models are predicated on three primary control dimensions: the identity of the requesting principal, the resource being accessed, and the action being performed. Existing authorization paradigms and access control mechanisms are largely designed around these dimensions. However, AI systems\u2014particularly agentic architectures\u2014introduce broader autonomy and decision-making capabilities that require an additional, context-aware control dimension. Specifically, authorization decisions must also incorporate the purpose and intent behind an agent\u2019s action, enabling governance frameworks to assess why an action is being performed in order to manage risk associated with expanded agency and non-deterministic behavior.</p> Integrated <p>AI systems are inherently distributed across implementation, hosting, functional, and operational domains. This distributed architecture necessitates the establishment of an integrated and centrally governed security framework. Each component of the agentic ecosystem must be secured in accordance with its specific risk profile and operating characteristics, while ensuring alignment with enterprise-wide security standards and a cohesive, end-to-end security posture.</p>"}]}